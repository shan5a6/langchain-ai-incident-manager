# Hugging Face (optional if using HF inference)
HF_API_TOKEN=YOUR_HF_TOKEN_HERE
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2


# Redpanda
KAFKA_BOOTSTRAP=redpanda:9092
KAFKA_TOPIC=incidents

# Qdrant
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_COLLECTION=incidents

# Postgres
POSTGRES_URL=postgresql://aiuser:aisecret@postgres:5432/incidents

# Hugging Face
HF_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
HF_API_TOKEN=          # optional if you use HF Inference API (not required for local sentence-transformers)

# Groq
GROQ_API_KEY=""
GROQ_API_URL=https://api.groq.ai/v1   # keep default unless you have another endpoint
GROQ_MODEL="llama-3.3-70b-versatile"

# Optional tuning
RAG_TOP_K=5

# Aws variables
export AWS_ACCESS_KEY_ID=""
export AWS_SECRET_ACCESS_KEY=""
export AWS_REGION=us-east-1
export SNS_TOPIC_ARN="arn:aws:sns:us-east-1:XXXXX:ai-incident-alerts"